{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/vol/cuda/11.2.1-cudnn8.1.0.77/targets/x86_64-linux/lib:/vol/cuda/11.2.1-cudnn8.1.0.77/lib64:'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/vol/bitbucket/ad6013/Research/gp-causal\")\n",
    "from models.PartObsBayesianGPLVM import PartObsBayesianGPLVM\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "from gpflow.config import default_float\n",
    "import tensorflow_probability as tfp\n",
    "from data.get_data import get_gauss_pairs_dataset, get_synthetic_dataset, get_simulated_pairs_dataset, get_multi_pairs_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, weight, target = get_gauss_pairs_dataset(\n",
    "    data_path='/vol/bitbucket/ad6013/Research/gp-causal/data/gauss_pairs/files'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = [244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_elbo(input, output, num_inducing):\n",
    "    # Need to find the ELBO for a noise model\n",
    "    linear_kernel = gpflow.kernels.Linear(variance=1)\n",
    "    kernel = linear_kernel\n",
    "\n",
    "    Z = gpflow.inducing_variables.InducingPoints(\n",
    "            np.linspace(input.min(), input.max(), num_inducing).reshape(-1, 1),\n",
    "        )\n",
    "    inducing_variable = Z\n",
    "\n",
    "    reg_gp_model = gpflow.models.SGPR(data=(input, output), kernel=kernel, inducing_variable=inducing_variable)\n",
    "    reg_gp_model.likelihood.variance = Parameter(\n",
    "        1 + 1e-20, transform=positive(lower=1e-6)\n",
    "    )\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "    opt_logs = opt.minimize(\n",
    "        reg_gp_model.training_loss,\n",
    "        reg_gp_model.trainable_variables,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options=dict(maxiter=200000),\n",
    "    )\n",
    "    loss = - reg_gp_model.elbo()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run number: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 305/2000 [03:24<18:55,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as -365.5438904136635 is less than -363.3321833195271\n",
      "Training everything\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gpflow.base import Parameter\n",
    "from gpflow.utilities import positive\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "for i in wrong:\n",
    "    print(f\"Run number: {i}\")\n",
    "    if target[i] > 0:\n",
    "        input = x[i]\n",
    "        output = y[i]\n",
    "    else:\n",
    "        input = y[i]\n",
    "        output = x[i]\n",
    "\n",
    "    # input = np.linspace(1, 100, 100)[:, None]\n",
    "    # output = input ** 2 + np.random.randn(100)[:, None]\n",
    "\n",
    "    # print(\"Data created\")\n",
    "\n",
    "    input = StandardScaler().fit_transform(input).astype(np.float64)\n",
    "    output = StandardScaler().fit_transform(output).astype(np.float64) \n",
    "\n",
    "    kernel_variance = 1.0\n",
    "    # Likelihood variance\n",
    "    kappa = np.random.uniform(\n",
    "        low=10.0, high=100, size=[1]\n",
    "    )\n",
    "    # Kernel lengthscale\n",
    "    lamda = np.random.uniform(\n",
    "        low=1.0, high=100, size=[1]\n",
    "    )\n",
    "\n",
    "    latent_dim = 1\n",
    "    num_inducing = 300\n",
    "\n",
    "    kernel_lengthscale = 1. / lamda\n",
    "    likelihood_variance = Parameter( 1. / (kappa ** 2), transform=positive(lower=1e-6))\n",
    "\n",
    "    kernel_lengthscale = 0.05\n",
    "    likelihood_variance = 0.01\n",
    "\n",
    "    # print(f\"Initial hyper: lengthscale - {kernel_lengthscale}, variance - {likelihood_variance.numpy()}\")\n",
    "\n",
    "\n",
    "    noise_loss = get_noise_elbo(\n",
    "        input=input,\n",
    "        output=output,\n",
    "        num_inducing=num_inducing\n",
    "    )\n",
    "\n",
    "    # Put in new values of hyperparams\n",
    "    # X_mean_init = output - reg_gp_model.predict_y(input)[0]\n",
    "    sq_exp = gpflow.kernels.SquaredExponential(\n",
    "        lengthscales=[kernel_lengthscale] + [kernel_lengthscale / 3]\n",
    "    )\n",
    "    sq_exp.variance.assign(1)\n",
    "    linear_kernel = gpflow.kernels.Linear(variance=1 + 1e-20)\n",
    "\n",
    "\n",
    "    # sq_exp = gpflow.kernels.SquaredExponential(lengthscales=[kernel_lengthscale[0], kernel_lengthscale[1]])\n",
    "\n",
    "    # linear_kernel = gpflow.kernels.Linear(variance=kernel_variance)\n",
    "    # poly_kernel = gpflow.kernels.Polynomial(degree=2, variance=kernel_variance)\n",
    "\n",
    "    # sq_exp.variance.assign(kernel_variance)\n",
    "\n",
    "    # quadratic_kernel = gpflow.kernels.Product([linear_kernel, linear_kernel_2])\n",
    "\n",
    "    # kernel = poly_kernel\n",
    "    kernel = gpflow.kernels.Sum([linear_kernel, sq_exp])\n",
    "    # kernel_2 = gpflow.kernels.Sum([linear_kernel_2, sq_exp_2])\n",
    "    # kernel = gpflow.kernels.SeparateIndependent(\n",
    "    #     [\n",
    "    #         kernel,  # This is k1, the kernel of f1\n",
    "    #         kernel_2  # this is k2, the kernel of f2\n",
    "    #     ]\n",
    "    # )\n",
    "\n",
    "\n",
    "    Z = gpflow.inducing_variables.InducingPoints(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(input.min(), input.max(), num_inducing).reshape(-1, 1),\n",
    "                np.random.randn(num_inducing, 1),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "    inducing_variable = Z\n",
    "    # Z_2 = gpflow.inducing_variables.InducingPoints(\n",
    "    #     np.concatenate(\n",
    "    #         [\n",
    "    #             np.linspace(input.min(), input.max(), num_inducing).reshape(-1, 1),\n",
    "    #             np.random.randn(num_inducing, 1),\n",
    "    #         ],\n",
    "    #         axis=1\n",
    "    #     )\n",
    "    # )\n",
    "    # inducing_variable = gpflow.inducing_variables.SeparateIndependentInducingVariables(\n",
    "    #     [\n",
    "    #         Z,  # This is U1 = f1(Z1)\n",
    "    #         Z_2,  # This is U2 = f2(Z2)\n",
    "    #     ]\n",
    "    # )\n",
    "    X_mean_init = 0.01 * tf.cast(output, default_float())\n",
    "    X_var_init = tf.cast(\n",
    "        np.random.uniform(0, 0.1, (input.shape[0], latent_dim)), default_float()\n",
    "    )\n",
    "\n",
    "    m = PartObsBayesianGPLVM(\n",
    "        data=output,\n",
    "        in_data=input,\n",
    "        kernel=kernel,\n",
    "        X_data_mean=X_mean_init,\n",
    "        X_data_var=X_var_init,\n",
    "        inducing_variable=inducing_variable,\n",
    "        jitter=1e-6\n",
    "    )\n",
    "    m.likelihood.variance = Parameter(\n",
    "        likelihood_variance + 1e-20, transform=positive(lower=1e-6)\n",
    "    )\n",
    "\n",
    "    loss_fn = m.training_loss_closure()\n",
    "\n",
    "    adam_vars = m.trainable_variables\n",
    "    adam_opt = tf.optimizers.Adam(0.05)\n",
    "    @tf.function\n",
    "    def optimisation_step():\n",
    "        adam_opt.minimize(loss_fn, adam_vars)\n",
    "\n",
    "    # epochs = int(20e3)\n",
    "    # log_freq = 100\n",
    "    # with trange(1, epochs + 1) as pbar:\n",
    "    #     losses = []\n",
    "    #     for epoch in pbar:\n",
    "    #         optimisation_step()\n",
    "    #         if epoch % log_freq == 0:\n",
    "    #             pbar.set_description(f\"ELBO {- m.elbo()}\")\n",
    "    #         if epoch % 1000 == 0:\n",
    "    #             obs_new = np.linspace(-5, 5, 1000)[:, None]\n",
    "\n",
    "    #             Xnew = tfp.distributions.Normal(loc=0, scale=1).sample([obs_new.shape[0], latent_dim])\n",
    "    #             Xnew = tf.cast(Xnew, dtype=default_float())\n",
    "    #             Xnew = tf.concat(\n",
    "    #                 [obs_new, Xnew], axis=1\n",
    "    #             )\n",
    "    #             pred_f_mean, pred_f_var = m.predict_y(\n",
    "    #                 Xnew=Xnew,\n",
    "    #             )\n",
    "    #             plt.scatter(input[:, 0], output[:, 0], c='r')\n",
    "    #             plt.plot(obs_new, pred_f_mean, c='b', alpha=0.2)\n",
    "    #             # plt.scatter(inducing_in, np.zeros(100) )\n",
    "    #             plt.fill_between(obs_new[:, 0], (pred_f_mean + 2 * np.sqrt(pred_f_var))[:, 0], (pred_f_mean - 2 * np.sqrt(pred_f_var))[:,0], alpha=0.5)\n",
    "    #             plt.show()\n",
    "    #             plt.close()\n",
    "    #         losses.append(- m.elbo())\n",
    "    #         if epoch > 101:\n",
    "    #             losses.pop(0)\n",
    "    #         if epoch > 1000 and np.abs(np.mean(losses[0:50]) - np.mean(losses[50:100])) < np.std(losses):\n",
    "    #             print(\"BREAKING!\")\n",
    "    #             break                \n",
    "\n",
    "    epochs = int(2e3)\n",
    "    with trange(1, epochs + 1) as pbar:\n",
    "        for epoch in pbar:\n",
    "            optimisation_step()\n",
    "            if - m.elbo() < noise_loss:\n",
    "                print(f\"Breaking as {- m.elbo()} is less than {noise_loss}\")\n",
    "                break\n",
    "\n",
    "\n",
    "    # tf.print(\"ELBO:\", - m.elbo())\n",
    "\n",
    "\n",
    "    # Train everything\n",
    "    # tf.print(\"Training everything\")\n",
    "    # gpflow.utilities.set_trainable(m.kernel, True)\n",
    "    # gpflow.utilities.set_trainable(m.likelihood, False)\n",
    "    # gpflow.utilities.set_trainable(m.X_data_mean , True)\n",
    "    # gpflow.utilities.set_trainable(m.X_data_var, True)\n",
    "    # gpflow.utilities.set_trainable(m.inducing_variable, True)\n",
    "    # opt = gpflow.optimizers.Scipy()\n",
    "    # opt_logs = opt.minimize(\n",
    "    #     m.training_loss,\n",
    "    #     m.trainable_variables,\n",
    "    #     method=\"L-BFGS-B\",\n",
    "    #     options=dict(maxiter=200000),\n",
    "    # )\n",
    "    tf.print(\"Training everything\")\n",
    "    gpflow.utilities.set_trainable(m.kernel, True)\n",
    "    gpflow.utilities.set_trainable(m.likelihood, True)\n",
    "    gpflow.utilities.set_trainable(m.X_data_mean , True)\n",
    "    gpflow.utilities.set_trainable(m.X_data_var, True)\n",
    "    gpflow.utilities.set_trainable(m.inducing_variable, True)\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "    opt_logs = opt.minimize(\n",
    "        m.training_loss,\n",
    "        m.trainable_variables,\n",
    "        options=dict(maxiter=200000),\n",
    "    )\n",
    "    tf.print(\"ELBO:\", - m.elbo(), noise_loss)\n",
    "\n",
    "    tf.print(f\"target: {target[i]}\")\n",
    "    loss = - m.elbo()\n",
    "\n",
    "    obs_new = np.linspace(-5, 5, 1000)[:, None]\n",
    "\n",
    "    Xnew = tfp.distributions.Normal(loc=0, scale=1).sample([obs_new.shape[0], latent_dim])\n",
    "    Xnew = tf.cast(Xnew, dtype=default_float())\n",
    "    Xnew = tf.concat(\n",
    "        [obs_new, Xnew], axis=1\n",
    "    )\n",
    "    pred_f_mean, pred_f_var = m.predict_y(\n",
    "        Xnew=Xnew,\n",
    "    )\n",
    "    plt.scatter(input[:, 0], output[:, 0], c='r')\n",
    "    plt.plot(obs_new, pred_f_mean, c='b', alpha=0.2)\n",
    "    # plt.scatter(inducing_in, np.zeros(100) )\n",
    "    plt.fill_between(obs_new[:, 0], (pred_f_mean + 2 * np.sqrt(pred_f_var))[:, 0], (pred_f_mean - 2 * np.sqrt(pred_f_var))[:,0], alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lt;gpflow.likelihoods.scalar_continuous.Gaussian object at 0x7ff5854ffac0&gt;\n",
       "<table>\n",
       "<thead>\n",
       "<tr><th>name             </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style=\"text-align: right;\">   value</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Gaussian.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style=\"text-align: right;\">0.661091</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<gpflow.likelihoods.scalar_continuous.Gaussian object at 0x7ff5854ffac0>\n",
       "╒═══════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
       "│ name              │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
       "╞═══════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
       "│ Gaussian.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.661091 │\n",
       "╘═══════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflux\n",
    "import numpy as np\n",
    "import tensorflow_probability as tfp\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_gpflux(\n",
    "    x,\n",
    "    y,\n",
    "    num_inducing,\n",
    "):\n",
    "    x = x.astype(np.float64)\n",
    "    y = y.astype(np.float64)\n",
    "    w_dim = 1\n",
    "    prior_means = np.zeros(w_dim)\n",
    "    prior_std = np.ones(w_dim)\n",
    "    encoder = gpflux.encoders.DirectlyParameterizedNormalDiag(x.shape[0], w_dim)\n",
    "    prior = tfp.distributions.MultivariateNormalDiag(prior_means, prior_std)\n",
    "    lv = gpflux.layers.LatentVariableLayer(prior, encoder)\n",
    "\n",
    "    linear_kernel = gpflow.kernels.Linear(variance=1.)\n",
    "    sq_exp = gpflow.kernels.SquaredExponential(lengthscales=[.05, .2], variance=1.)\n",
    "    kernel = gpflow.kernels.Sum([linear_kernel, sq_exp])\n",
    "\n",
    "    inducing_variable = gpflow.inducing_variables.InducingPoints(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(x.min(), x.max(), num_inducing).reshape(-1, 1),\n",
    "                np.random.randn(num_inducing, 1),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "    gp_layer = gpflux.layers.GPLayer(\n",
    "        kernel,\n",
    "        inducing_variable,\n",
    "        num_data=x.shape[0],\n",
    "        num_latent_gps=1,\n",
    "        mean_function=gpflow.mean_functions.Zero(),\n",
    "    )\n",
    "\n",
    "\n",
    "    kernel = gpflow.kernels.SquaredExponential()\n",
    "    inducing_variable = gpflow.inducing_variables.InducingPoints(\n",
    "        np.random.randn(num_inducing, 1),\n",
    "    )\n",
    "    gp_layer2 = gpflux.layers.GPLayer(\n",
    "        kernel,\n",
    "        inducing_variable,\n",
    "        num_data=x.shape[0],\n",
    "        num_latent_gps=1,\n",
    "        mean_function=gpflow.mean_functions.Identity(),\n",
    "    )\n",
    "    gp_layer2.q_sqrt.assign(gp_layer.q_sqrt * 1e-5);\n",
    "\n",
    "    gp_layer3 = gpflux.layers.GPLayer(\n",
    "        kernel,\n",
    "        inducing_variable,\n",
    "        num_data=x.shape[0],\n",
    "        num_latent_gps=1,\n",
    "        mean_function=gpflow.mean_functions.Identity(),\n",
    "    )\n",
    "    gp_layer3.q_sqrt.assign(gp_layer.q_sqrt * 1e-5);\n",
    "\n",
    "    likelihood_layer = gpflux.layers.LikelihoodLayer(gpflow.likelihoods.Gaussian(0.01))\n",
    "    # gpflow.set_trainable(likelihood_layer, False)\n",
    "    dgp = gpflux.models.DeepGP([lv, gp_layer], likelihood_layer)\n",
    "    tf.print( - dgp.elbo((x, y)))\n",
    "    model = dgp.as_training_model()\n",
    "    model.compile(tf.optimizers.Adam(0.05))\n",
    "\n",
    "    history = model.fit({\"inputs\": tf.cast(x, tf.float64), \"targets\": tf.cast(y, tf.float64)}, epochs=int(100e3), verbose=0, batch_size=x.shape[0], shuffle=False)\n",
    "\n",
    "    loss = - dgp.elbo((x, y))\n",
    " \n",
    "    # Plot the fit to see if everything is ok\n",
    "    obs_new = np.linspace(-5, 5, 1000)[:, None]\n",
    "\n",
    "    def predict_y_samples(prediction_model, Xs):\n",
    "        out = prediction_model(Xs)\n",
    "        s = out.y_mean + out.y_var ** .5 * tf.random.normal(tf.shape(out.y_mean), dtype=out.y_mean.dtype)\n",
    "        return out.y_mean[:, 0], out.y_var[:, 0]\n",
    "\n",
    "    pred_y_mean, pred_y_var = predict_y_samples(dgp.as_prediction_model(), obs_new)\n",
    "    textstr = 'elbo=%.2f\\n'%(\n",
    "        loss\n",
    "    )\n",
    "    plt.text(-17, 0, textstr, fontsize=8)\n",
    "    plt.scatter(x, y, c='r')\n",
    "    plt.plot(obs_new, pred_y_mean, c='b', alpha=0.6)\n",
    "    plt.fill_between(obs_new[:, 0], (pred_y_mean + 2 * np.sqrt(pred_y_var)), (pred_y_mean - 2 * np.sqrt(pred_y_var)), alpha=0.5)\n",
    "    plt.subplots_adjust(left=0.25)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 288\n",
      "X -> Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3162011/836381768.py:4: DeprecationWarning: Call to deprecated class TrackableLayer. (GPflux's `TrackableLayer` was prior to TF2.5 used to collect GPflow variables in subclassed layers. As of TF 2.5, `tf.Module` supports this natively and there is no need for `TrackableLayer` anymore. It will be removed in GPflux version `1.0.0`.)\n",
      "  history_x_y = train_gpflux(x[i], y[i], 200)\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/gpflux/layers/gp_layer.py:198: UserWarning: Could not verify the compatibility of the `kernel`, `inducing_variable` and `mean_function`. We advise using `gpflux.helpers.construct_*` to create compatible kernels and inducing variables. As `num_latent_gps=1` has been specified explicitly, this will be used to create the `q_mu` and `q_sqrt` parameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262545.721852091\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRun: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mX -> Y\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m history_x_y \u001b[39m=\u001b[39m train_gpflux(x[i], y[i], \u001b[39m200\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000008vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mY -> X\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m history_y_x \u001b[39m=\u001b[39m train_gpflux(y[i], x[i], \u001b[39m200\u001b[39m)\n",
      "\u001b[1;32m/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb Cell 8'\u001b[0m in \u001b[0;36mtrain_gpflux\u001b[0;34m(x, y, num_inducing)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000007vscode-remote?line=72'>73</a>\u001b[0m model \u001b[39m=\u001b[39m dgp\u001b[39m.\u001b[39mas_training_model()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000007vscode-remote?line=73'>74</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(tf\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(\u001b[39m0.05\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000007vscode-remote?line=75'>76</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit({\u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: tf\u001b[39m.\u001b[39;49mcast(x, tf\u001b[39m.\u001b[39;49mfloat64), \u001b[39m\"\u001b[39;49m\u001b[39mtargets\u001b[39;49m\u001b[39m\"\u001b[39;49m: tf\u001b[39m.\u001b[39;49mcast(y, tf\u001b[39m.\u001b[39;49mfloat64)}, epochs\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39m100e3\u001b[39;49m), verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mx\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000007vscode-remote?line=77'>78</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m dgp\u001b[39m.\u001b[39melbo((x, y))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000007vscode-remote?line=79'>80</a>\u001b[0m \u001b[39m# Plot the fit to see if everything is ok\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py:1373\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=1370'>1371</a>\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=1371'>1372</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():\n\u001b[0;32m-> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=1372'>1373</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_metrics()\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=1373'>1374</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=1374'>1375</a>\u001b[0m   \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py:2034\u001b[0m, in \u001b[0;36mModel.reset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=2014'>2015</a>\u001b[0m \u001b[39m\"\"\"Resets the state of all the metrics in the model.\u001b[39;00m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=2015'>2016</a>\u001b[0m \n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=2016'>2017</a>\u001b[0m \u001b[39mExamples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=2030'>2031</a>\u001b[0m \n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=2031'>2032</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=2032'>2033</a>\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics:\n\u001b[0;32m-> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/engine/training.py?line=2033'>2034</a>\u001b[0m   m\u001b[39m.\u001b[39;49mreset_state()\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/metrics.py:267\u001b[0m, in \u001b[0;36mMetric.reset_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/metrics.py?line=264'>265</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_states()\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/metrics.py?line=265'>266</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/metrics.py?line=266'>267</a>\u001b[0m   backend\u001b[39m.\u001b[39;49mbatch_set_value([(v, \u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariables])\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1079'>1080</a>\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1080'>1081</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1081'>1082</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1082'>1083</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1083'>1084</a>\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1084'>1085</a>\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1085'>1086</a>\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/backend.py:4019\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/backend.py?line=4016'>4017</a>\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/backend.py?line=4017'>4018</a>\u001b[0m   \u001b[39mfor\u001b[39;00m x, value \u001b[39min\u001b[39;00m tuples:\n\u001b[0;32m-> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/backend.py?line=4018'>4019</a>\u001b[0m     x\u001b[39m.\u001b[39;49massign(np\u001b[39m.\u001b[39;49masarray(value, dtype\u001b[39m=\u001b[39;49mdtype_numpy(x)))\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/backend.py?line=4019'>4020</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/keras/backend.py?line=4020'>4021</a>\u001b[0m   \u001b[39mwith\u001b[39;00m get_graph()\u001b[39m.\u001b[39mas_default():\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:934\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py?line=930'>931</a>\u001b[0m \u001b[39m# Note: not depending on the cached value here since this can be used to\u001b[39;00m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py?line=931'>932</a>\u001b[0m \u001b[39m# initialize the variable.\u001b[39;00m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py?line=932'>933</a>\u001b[0m \u001b[39mwith\u001b[39;00m _handle_graph(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle):\n\u001b[0;32m--> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py?line=933'>934</a>\u001b[0m   value_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(value, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py?line=934'>935</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape\u001b[39m.\u001b[39mis_compatible_with(value_tensor\u001b[39m.\u001b[39mshape):\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py?line=935'>936</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py?line=180'>181</a>\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py?line=181'>182</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py?line=182'>183</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1689'>1690</a>\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1690'>1691</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1691'>1692</a>\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1693'>1694</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1694'>1695</a>\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1696'>1697</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1697'>1698</a>\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py?line=45'>46</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py?line=46'>47</a>\u001b[0m   \u001b[39mdel\u001b[39;00m as_ref  \u001b[39m# Unused.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py?line=47'>48</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(value, dtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=169'>170</a>\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=170'>171</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=171'>172</a>\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=172'>173</a>\u001b[0m \n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=173'>174</a>\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=264'>265</a>\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=265'>266</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=266'>267</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=267'>268</a>\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=276'>277</a>\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=277'>278</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=278'>279</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=280'>281</a>\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=281'>282</a>\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=301'>302</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=302'>303</a>\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=303'>304</a>\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=304'>305</a>\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=305'>306</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=99'>100</a>\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=100'>101</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> <a href='file:///vol/bitbucket/ad6013/envs/gp-causal-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in wrong:\n",
    "    print(f\"Run: {i}\")\n",
    "    print(\"X -> Y\")\n",
    "    history_x_y = train_gpflux(x[i], y[i], 200)\n",
    "    print(\"Y -> X\")\n",
    "    history_y_x = train_gpflux(y[i], x[i], 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmiasma.doc.ic.ac.uk/vol/bitbucket/ad6013/Research/gp-causal/notebooks/gplvm.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a29dfc3a58ca91141e6b31b77b731cbdeae0adeabff34291556b287f724fc891"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('gp-causal-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
