{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/vol/bitbucket/ad6013/Research/gp-causal\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from data import get_data\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to load all the data\n",
    "def return_adam_files(data_name):\n",
    "    files = [\n",
    "        f\"fullscore-{data_name}_pairs-gplvm_adam-reinit2-numind200_start:{i}_end:{i+20}.p\"\n",
    "        for i in np.linspace(0, 280, 15, dtype=int)\n",
    "    ]\n",
    "    return files\n",
    "\n",
    "\n",
    "def return_bfgs_files(data_name):\n",
    "    files = [\n",
    "        f\"fullscore-{data_name}-gplvm-reinit20-numind200_start:{i}_end:{i+10}.p\"\n",
    "        for i in np.linspace(0, 90, 10, dtype=int)\n",
    "    ]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 90, 10, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file_scores_into_dict(files):\n",
    "    \"\"\"\n",
    "    Convert files saved by runs to one big dict of scores with the key being\n",
    "    the run_number and the value being the tuple of a tuple of scores of the\n",
    "    form ( (x, y|x), (y, x|y) )\n",
    "    \"\"\"\n",
    "    work_dir = \"/vol/bitbucket/ad6013/Research/gp-causal\"\n",
    "    all_scores = {}\n",
    "    for file_idx in range(len(files)):\n",
    "        # Open  file results\n",
    "        with open(f\"{work_dir}/results/{files[file_idx]}\", \"rb\") as f:\n",
    "            results = pickle.load(f)\n",
    "        for i in range(len(results['scores'])):\n",
    "            idx = 10 * file_idx + i\n",
    "            all_scores[idx] = results[\"scores\"][i]\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_between_two_scores(scores_1, scores_2):\n",
    "    \"\"\"\n",
    "    Scores should be dict with values of tuples of tuples\n",
    "    ( (x, y|x), (y, x|y) )\n",
    "    \"\"\"\n",
    "    all_scores = {}\n",
    "    for idx in scores_1.keys(): \n",
    "        if idx not in scores_2.keys():\n",
    "            raise ValueError(f\"Run idx mismatch for run {idx}\")\n",
    "        else:\n",
    "            scores_1_idx = scores_1[idx]\n",
    "            scores_2_idx = scores_2[idx]\n",
    "            min_score_x = min(scores_1_idx[0][0], scores_2_idx[0][0])\n",
    "            min_score_y_x = min(scores_1_idx[0][1], scores_2_idx[0][1]) \n",
    "            min_score_y = min(scores_1_idx[1][0], scores_2_idx[1][0])\n",
    "            min_score_x_y = min(scores_1_idx[1][1], scores_2_idx[1][1]) \n",
    "            final_scores = (\n",
    "                (min_score_x, min_score_y_x),\n",
    "                (min_score_y, min_score_x_y)\n",
    "            )\n",
    "            all_scores[idx] = final_scores\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_between_marginal_and_full_scores(marginal_score, full_score):\n",
    "    \"\"\"\n",
    "    Scores should be dict with values of tuples of tuples\n",
    "    maringal_score = (x, y)\n",
    "    full_score: ( (x, y|x), (y, x|y) )\n",
    "    \"\"\"\n",
    "    all_scores = {}\n",
    "    for idx in marginal_score.keys(): \n",
    "        if idx not in full_score.keys():\n",
    "            pass\n",
    "            # raise ValueError(f\"Run idx mismatch for run {idx}\")\n",
    "        else:\n",
    "            scores_marg_idx = marginal_score[idx]\n",
    "            scores_full_idx = full_score[idx]\n",
    "            # min_score_x = min(scores_marg_idx[0], scores_full_idx[0][0])\n",
    "            min_score_x = scores_marg_idx[0]\n",
    "            min_score_y_x = scores_full_idx[0][1] \n",
    "            # min_score_y = min(scores_marg_idx[1], scores_full_idx[1][0])\n",
    "            min_score_y =  scores_marg_idx[1] \n",
    "            min_score_x_y = scores_full_idx[1][1]\n",
    "            final_scores = (\n",
    "                (min_score_x, min_score_y_x),\n",
    "                (min_score_y, min_score_x_y)\n",
    "            )\n",
    "            all_scores[idx] = final_scores\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_scores(data_name, scores):\n",
    "    work_dir = \"/vol/bitbucket/ad6013/Research/gp-causal\"\n",
    "    data_get = getattr(get_data, f\"get_tubingen_pairs_dataset\")\n",
    "    x, y, weight, target = data_get(data_path=f\"{work_dir}/data/pairs/files\")\n",
    "\n",
    "    y_scores = []\n",
    "    y_labels = []\n",
    "    for idx in scores.keys():\n",
    "        causal = sum(scores[idx][0])\n",
    "        anti_causal = sum(scores[idx][1])\n",
    "        final_score = - causal + anti_causal \n",
    "        y_labels.append(target[idx])\n",
    "        y_scores.append(final_score)\n",
    "\n",
    "    random_choice = np.random.choice(len(y_labels), size=len(y_labels) // 2)\n",
    "    for i in random_choice:\n",
    "        y_labels[i] *= -1\n",
    "        y_scores[i] *= -1\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_labels, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load cause-effect pairs: 100%|██████████| 100/100 [00:00<00:00, 226.24it/s]\n"
     ]
    }
   ],
   "source": [
    "data_name = \"cep\"\n",
    "# adam_files = return_adam_files(data_name=data_name)\n",
    "bfgs_files = return_bfgs_files(data_name=data_name)\n",
    "# adam_scores = convert_file_scores_into_dict(adam_files)\n",
    "bfgs_scores = convert_file_scores_into_dict(bfgs_files)\n",
    "# scores = return_best_between_two_scores(adam_scores, bfgs_scores)\n",
    "adam_bfgs_auc = get_auc_scores(data_name, bfgs_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6986817325800376"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_bfgs_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesgmm_score(train_data, n_components):\n",
    "    model = BayesianGaussianMixture(\n",
    "        n_components=n_components,\n",
    "        max_iter=int(1e6),\n",
    "    ).fit(train_data)\n",
    "    return - np.sum(model.score_samples(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_bayesian_gmm_scores(data_name, num_restarts):\n",
    "    \"\"\"\n",
    "    Will return scores of Bayesian GMM for a dataset.\n",
    "    \"\"\"\n",
    "    work_dir = \"/vol/bitbucket/ad6013/Research/gp-causal\"\n",
    "    data_get = getattr(get_data, f\"get_tubingen_pairs_dataset\")\n",
    "    x, y, weight, target = data_get(data_path=f\"{work_dir}/data/pairs/files\")\n",
    "\n",
    "    all_scores = {}\n",
    "    n_components_array = np.arange(3, 10)\n",
    "    for idx in tqdm(range(len(x)), desc=\"Running BayesGMM\"):\n",
    "        run_score_x = []\n",
    "        run_score_y = []\n",
    "        for i in range(num_restarts):\n",
    "            train_x = x[idx]\n",
    "            train_y = y[idx]\n",
    "            # Normalise the data\n",
    "            train_x = StandardScaler().fit_transform(train_x).astype(np.float64)\n",
    "            train_y = StandardScaler().fit_transform(train_y).astype(np.float64)\n",
    "\n",
    "            n_components = np.random.choice(n_components_array)\n",
    "            x_score = bayesgmm_score(\n",
    "                train_x,\n",
    "                n_components=n_components,\n",
    "            )\n",
    "            y_score = bayesgmm_score(\n",
    "                train_y,\n",
    "                n_components=n_components,\n",
    "            )\n",
    "            \n",
    "            run_score_x.append(x_score)\n",
    "            run_score_y.append(y_score)\n",
    "     \n",
    "        all_scores[idx] = (min(run_score_x), min(run_score_y))\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load cause-effect pairs: 100%|██████████| 100/100 [00:00<00:00, 226.01it/s]\n",
      "Running BayesGMM:  46%|████▌     | 46/100 [35:01<2:55:09, 194.61s/it]/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "Running BayesGMM:  69%|██████▉   | 69/100 [43:27<59:03, 114.30s/it]  /vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "Running BayesGMM:  70%|███████   | 70/100 [44:06<45:55, 91.83s/it] /vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "/vol/bitbucket/ad6013/envs/gp-causal-3.8/lib/python3.8/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  cluster.KMeans(\n",
      "Running BayesGMM: 100%|██████████| 100/100 [1:14:13<00:00, 44.54s/it]\n"
     ]
    }
   ],
   "source": [
    "bayesgmm_scores = return_bayesian_gmm_scores(data_name, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (369.5587079334272, 432.2758528852618),\n",
       " 1: (369.57397618367474, 412.7270931700559),\n",
       " 2: (483.58177918746304, 432.2596955210503),\n",
       " 3: (369.6072231599737, 487.5836857519792),\n",
       " 4: (2949.86750393716, 5711.104619493236),\n",
       " 5: (2949.938093768742, 5660.233072649171),\n",
       " 6: (3118.874831921589, 5710.901658863453),\n",
       " 7: (3542.263645623937, 5565.796772873109),\n",
       " 8: (3228.580986572403, 5648.988607719781),\n",
       " 9: (2950.0270968451127, 5588.158567716921),\n",
       " 10: (3228.6610022749683, 5623.140719181346),\n",
       " 11: (6755.152971496134, 4903.097562495011),\n",
       " 12: (423.69066227880114, 533.0335384726119),\n",
       " 13: (485.7980447981433, 533.0631353373961),\n",
       " 14: (506.514793089718, 533.0663650028949),\n",
       " 15: (485.8010548676707, 555.4118492423411),\n",
       " 16: (6914.256460307017, -2635.21337778583),\n",
       " 17: (354.7909542077501, 376.76382737265874),\n",
       " 18: (172.73293505016574, 248.38183499647278),\n",
       " 19: (461.2718400951087, 432.25423162648946),\n",
       " 20: (483.5823225788797, 412.7263486030435),\n",
       " 21: (634.7596084765026, 569.7802909631315),\n",
       " 22: (636.5321767039892, 610.9025264396917),\n",
       " 23: (635.165251301111, 601.1926044345987),\n",
       " 24: (1370.7557957205677, 1424.6972146866572),\n",
       " 25: (469.23834314083757, 1424.4685826581474),\n",
       " 26: (-84.56856616156776, 1424.5602362795253),\n",
       " 27: (1391.2030161711787, 1424.646582437228),\n",
       " 28: (677.8205861028935, 1424.6649891891743),\n",
       " 29: (1389.7215750388782, 1424.6656234105515),\n",
       " 30: (1411.910909298569, 1424.643071554597),\n",
       " 31: (4.079076621220935, 1424.535912484841),\n",
       " 32: (345.7264893005903, 482.73500470764805),\n",
       " 33: (345.83966805028, 474.8291837423813),\n",
       " 34: (345.67524575510043, 354.2076931922021),\n",
       " 35: (345.73146167546196, 402.27975972230206),\n",
       " 36: (345.7481225783971, 283.5050029992449),\n",
       " 37: (858.1719139475836, 1054.9119883187798),\n",
       " 38: (425.2294127158192, 437.7724370524131),\n",
       " 39: (830.927203665801, 1034.2991919686708),\n",
       " 40: (861.1601313392393, 1045.576081997456),\n",
       " 41: (11670.762592459201, 12837.478641083648),\n",
       " 42: (11226.270150273485, 11334.739299661125),\n",
       " 43: (4821.69695222336, 4500.835931345039),\n",
       " 44: (12591.079254086359, 13236.112666418805),\n",
       " 45: (9942.490645267157, 9663.488415194253),\n",
       " 46: (-115.85068243548415, 283.5907574941525),\n",
       " 47: (222.6640147656658, 232.5170815683216),\n",
       " 48: (491.8032805129292, 515.9020076947443),\n",
       " 49: (499.41637790676884, 514.5430353759434),\n",
       " 50: (500.87047229742086, 510.6911986901275),\n",
       " 51: (-48423.09340178635, -49219.69113172652),\n",
       " 52: (-1359.1581224891795, 443.61714130734543),\n",
       " 53: (-1521.743183445606, -753.2009550754456),\n",
       " 54: (-66.00509437982707, 460.8289109043788),\n",
       " 55: (260.8052721884163, 231.38100626566825),\n",
       " 56: (260.8163060490488, 236.11823277146462),\n",
       " 57: (260.8515137890399, 240.14106417505087),\n",
       " 58: (260.84402635278855, 242.92790856830237),\n",
       " 59: (260.91221323750074, 243.76492241724313),\n",
       " 60: (260.80931313821605, 247.56080351957104),\n",
       " 61: (260.82812360780866, 250.8375022703578),\n",
       " 62: (260.7970379283193, 250.01322363798337),\n",
       " 63: (177.32706948756902, 186.51452267171402),\n",
       " 64: (1794.3850364170567, 1787.3685390209814),\n",
       " 65: (1836.1415351788833, 1853.0554238867908),\n",
       " 66: (1853.0550853610935, 1835.7554057359673),\n",
       " 67: (-145.65212115278982, -699.1838717481196),\n",
       " 68: (21166.49984856804, 6187.169677354892),\n",
       " 69: (5729.089090386578, -8790.820900846207),\n",
       " 70: (17.67295727271756, 38.379453242484466),\n",
       " 71: (1911.2140317043643, 2294.197575752442),\n",
       " 72: (3859.7195158605364, 3316.492166011016),\n",
       " 73: (117.2574944438162, 246.81899257925946),\n",
       " 74: (130.30809919911349, 197.00645038710041),\n",
       " 75: (480.32449230227854, 477.405281708075),\n",
       " 76: (10249.841514593643, 11761.277402154494),\n",
       " 77: (912.2350716745091, 998.7971552268941),\n",
       " 78: (967.2297760986855, 998.8690011932538),\n",
       " 79: (688.5526752760766, 998.8690011932538),\n",
       " 80: (510.30846488099485, 507.070708622736),\n",
       " 81: (502.3804228328962, 464.32879198043645),\n",
       " 82: (490.7483032583042, 405.230647269035),\n",
       " 83: (4322.789532074092, 4311.600918383579),\n",
       " 84: (1297.9410606887973, 1406.3875495737082),\n",
       " 85: (835.6470960616169, 921.9104199502109),\n",
       " 86: (10560.435614305772, -4761.632560006001),\n",
       " 87: (349.6910138801075, 344.4685732997007),\n",
       " 88: (181.3017734222194, 186.99909048959574),\n",
       " 89: (178.16186189963716, 179.89030615582215),\n",
       " 90: (178.15608793294666, 208.84025096143557),\n",
       " 91: (179.5791483351004, 190.94397092680498),\n",
       " 92: (579.7409194648851, 509.3097629322901),\n",
       " 93: (12071.409317984348, 12617.36387660205),\n",
       " 94: (12071.46494692736, 12311.631941526455),\n",
       " 95: (12617.842944374584, 12311.47171107173),\n",
       " 96: (287.7322807962681, 283.4636702652441),\n",
       " 97: (125.31757326516272, 124.88534846194528),\n",
       " 98: (2937.0607062750455, 3112.8444866128043),\n",
       " 99: (289.66533242705157, 290.8020210066943)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesgmm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ((380.4152794302315, 212.44111712680163),\n",
       "  (453.78477419861576, 199.2502760255514)),\n",
       " 1: ((380.4152794302315, 302.66297746126816),\n",
       "  (433.92545168799893, 280.436275773376)),\n",
       " 2: ((495.86265291184725, 424.01120420151096),\n",
       "  (453.78477419861576, 465.37694569215864)),\n",
       " 3: ((380.41458332561797, 487.52499522561357),\n",
       "  (495.2095490215442, 397.340589947514)),\n",
       " 4: ((380.41458332561797, 487.52499522561357),\n",
       "  (495.2095490215442, 397.340589947514)),\n",
       " 5: ((380.41458332561797, 487.52499522561357),\n",
       "  (495.2095490215442, 397.340589947514)),\n",
       " 10: ((-218.73398362418993, 4173.638674743706),\n",
       "  (5634.863776636774, 2329.864293066208)),\n",
       " 11: ((5416.376517551311, 4244.62228851653),\n",
       "  (4166.258204279944, 5426.640553992867)),\n",
       " 12: ((398.2047316557823, 294.4956044467922),\n",
       "  (548.5704450445514, 207.1354560890768)),\n",
       " 13: ((398.2047316557823, 294.4956044467922),\n",
       "  (548.5704268674258, 207.1354560890768)),\n",
       " 14: ((398.2047316557823, 277.9452768409954),\n",
       "  (548.570403729393, 207.1354560890768)),\n",
       " 15: ((398.2047316557823, 277.9452768409954),\n",
       "  (548.570403729393, 207.1354560890768)),\n",
       " 16: ((398.2047316557823, 277.9452768409954),\n",
       "  (-1872.0893477142563, 207.1354560890768)),\n",
       " 17: ((341.85120099379765, 160.17455102025156),\n",
       "  (-1872.0893477142563, 132.82971531602345)),\n",
       " 18: ((198.85926079037813, 135.69644986318883),\n",
       "  (-1872.0893477142563, 83.80455886645916)),\n",
       " 19: ((198.85926079037813, 135.69644986318883),\n",
       "  (-1872.0893477142563, 83.80455886645916)),\n",
       " 20: ((495.8626544067702, 407.17678175273295),\n",
       "  (433.9254379191484, 456.00589091851583)),\n",
       " 21: ((638.5223408269444, 472.1509686072268),\n",
       "  (339.98184765115775, 611.7911289988792)),\n",
       " 22: ((641.3602185027344, 547.7805780281839),\n",
       "  (633.0545786508686, 577.8649503385082)),\n",
       " 23: ((639.9412797946618, 607.3169338069507),\n",
       "  (618.8006226844496, 634.616888086042)),\n",
       " 24: ((1381.9296097232454, 1290.445018353046),\n",
       "  (1442.555488166829, 1263.0012586001067)),\n",
       " 25: ((-514.7250751034762, 1361.2355256378687),\n",
       "  (1442.5556151482656, -523.1073862061949)),\n",
       " 26: ((-1036.1419137691942, 1431.0805693074744),\n",
       "  (1442.555577571301, -947.7852793059187)),\n",
       " 27: ((1040.5687435313394, 1344.554321640729),\n",
       "  (1442.5555288111987, 1157.5590168992994)),\n",
       " 28: ((-22.325237498032948, 1381.9464176831636),\n",
       "  (1442.5555231096969, -34.56754368665315)),\n",
       " 29: ((1242.9388844458963, 1378.9993376501805),\n",
       "  (1442.5555027092987, 1273.0551536812654)),\n",
       " 30: ((1333.640632076128, 1428.3809828167527),\n",
       "  (1442.5556580172597, 1340.4373062137774)),\n",
       " 31: ((-1027.1397676129423, 1222.521531292131),\n",
       "  (1442.555577571301, -677.5263048996499)),\n",
       " 32: ((-61.15530244350998, 474.25928292271766),\n",
       "  (177.25988415052575, 200.66226232773306)),\n",
       " 33: ((-54.04737272912962, 489.7901601324363),\n",
       "  (487.3281653401709, -231.43385043045646)),\n",
       " 34: ((-60.965540271221016, 379.63425952019963),\n",
       "  (378.3568789422907, 250.16322287186904)),\n",
       " 35: ((-54.01499206593212, 415.2450101454039),\n",
       "  (424.70447448760797, 14.018823961254611)),\n",
       " 36: ((-57.57726758212539, 295.12346988822605),\n",
       "  (301.05794463586506, 60.899331951256954)),\n",
       " 37: ((823.2525820495875, 1060.2298423902262),\n",
       "  (1070.6591953365478, 836.7773115100458)),\n",
       " 38: ((418.2270374172365, 449.63727097116157),\n",
       "  (457.8209543846949, 426.12423914791975)),\n",
       " 39: ((782.0279490869016, 1002.5968465591609),\n",
       "  (474.95336443088536, 794.5505727108025)),\n",
       " 40: ((812.2733874755495, 1042.4325140849735),\n",
       "  (1060.899775402022, 829.2114916733681)),\n",
       " 41: ((5035.586975632537, 5634.273505965681),\n",
       "  (5628.385069750915, 5049.167229099381)),\n",
       " 42: ((4403.438044268356, 5634.273505965681),\n",
       "  (4433.4508830831, 5049.167229099381)),\n",
       " 43: ((1932.343118349776, 1959.7801413584257),\n",
       "  (1798.8661819795561, 5049.167229099381)),\n",
       " 44: ((1932.343118349776, 1959.7801413584257),\n",
       "  (1798.8661819795561, 5049.167229099381)),\n",
       " 45: ((1932.343118349776, 1959.7801413584257),\n",
       "  (1798.8661819795561, 3817.9826813473483)),\n",
       " 46: ((-667.3346362060031, 281.38675884838153),\n",
       "  (293.46757933147046, 355.5143838768745)),\n",
       " 47: ((-667.3346362060031, 223.95826038780928),\n",
       "  (241.47021629942617, 223.95826000704795)),\n",
       " 48: ((-667.3346362060031, 223.95826038780928),\n",
       "  (241.47021629942617, 223.95826000704795)),\n",
       " 49: ((-667.3346362060031, 223.95826038780928),\n",
       "  (241.47021629942617, 223.95826000704795)),\n",
       " 50: ((517.1140030359618, 487.904108143384),\n",
       "  (517.9125658129263, 485.73964184053716)),\n",
       " 51: ((272.43619927058114, 225.64806031042144),\n",
       "  (246.98532926534, 249.31528097950883)),\n",
       " 52: ((272.43619932621107, 237.42256795629814),\n",
       "  (253.0963749594522, 256.64766764383955)),\n",
       " 53: ((272.4361989501835, 239.44217026597013),\n",
       "  (254.710337416411, 256.44486261943456)),\n",
       " 54: ((272.4361991011388, 237.60129106164138),\n",
       "  (254.1882255684717, 256.17283509999646)),\n",
       " 55: ((272.4361991762253, 247.78559951489615),\n",
       "  (256.81643825080744, 259.987225179557)),\n",
       " 60: ((272.43619927058114, 251.28500846543196),\n",
       "  (259.85608458787294, 262.4809765431715)),\n",
       " 61: ((272.43619932621107, 252.5578321717773),\n",
       "  (261.4762152266024, 263.2145007869523)),\n",
       " 62: ((272.4361989501835, 247.92252821907158),\n",
       "  (262.42040275702044, 260.51819220123525)),\n",
       " 63: ((124.13644461004958, 112.84266090348876),\n",
       "  (189.385050589917, 91.5474003424643)),\n",
       " 64: ((1535.0155496305451, 1555.644351985126),\n",
       "  (1651.7356154548506, 1563.0788608113985)),\n",
       " 65: ((1815.0170765632083, 1116.02233772314),\n",
       "  (1846.6475475416128, 1102.6329435474067)),\n",
       " 66: ((1840.977609648061, 1356.6077638974343),\n",
       "  (1842.3376871157016, 1372.1610450634196)),\n",
       " 67: ((-136.01932008952508, -1243.366466718354),\n",
       "  (-1233.14633205412, -335.7499388106501)),\n",
       " 68: ((5215.08263121295, -2155.3926752861225),\n",
       "  (-1738.1716378440506, 5222.61315265498)),\n",
       " 70: ((1882.3279692523884, 2280.126516992707),\n",
       "  (2312.581290725852, 1899.5876441707242)),\n",
       " 71: ((3064.4271374962154, 2723.457524959318),\n",
       "  (2590.8549615371685, 3203.6127925300207)),\n",
       " 72: ((111.23245454957942, 182.68645867930522),\n",
       "  (262.2278872534728, 27.79729764230285)),\n",
       " 73: ((111.23245454957942, 135.62148737219388),\n",
       "  (197.56923138242166, 27.79729764230285)),\n",
       " 74: ((111.23245454957942, 135.62148737219388),\n",
       "  (197.56923138242166, 27.79729764230285)),\n",
       " 75: ((111.23245454957942, 135.62148737219388),\n",
       "  (197.56923138242166, 27.79729764230285)),\n",
       " 76: ((111.23245454957942, 135.62148737219388),\n",
       "  (197.56923138242166, 27.79729764230285)),\n",
       " 77: ((111.23245454957942, 135.62148737219388),\n",
       "  (197.56923138242166, 27.79729764230285)),\n",
       " 78: ((111.23245454957942, 135.62148737219388),\n",
       "  (197.56923138242166, 27.79729764230285)),\n",
       " 80: ((517.9125691308662, 389.0397054082574),\n",
       "  (517.9125661960568, 383.69409901630013)),\n",
       " 81: ((517.0018119804303, 304.7999588698568),\n",
       "  (485.5976523952006, 343.1713849666404)),\n",
       " 82: ((510.3464701831082, 164.15917464857012),\n",
       "  (423.2542732148904, 254.26219785915504)),\n",
       " 83: ((4347.03640285145, -2970.7646418395525),\n",
       "  (4335.670970667854, -2958.103458030143)),\n",
       " 84: ((-47.17885081874783, -2970.7646418395525),\n",
       "  (1410.424938949933, -2958.103458030143)),\n",
       " 85: ((-47.17885081874783, -2970.7646418395525),\n",
       "  (661.7966847986118, -2958.103458030143)),\n",
       " 86: ((-47.17885081874783, -2970.7646418395525),\n",
       "  (-1928.6481365736763, -2958.103458030143)),\n",
       " 87: ((-47.17885081874783, -2970.7646418395525),\n",
       "  (-1928.6481365736763, -2958.103458030143)),\n",
       " 90: ((190.7975500135617, 142.34032843432072),\n",
       "  (211.42184176390137, 126.42178038506427)),\n",
       " 91: ((191.90158388707312, 91.75795215489376),\n",
       "  (207.61018624566725, 88.81545386838685)),\n",
       " 92: ((602.233167946878, 211.8788637985092),\n",
       "  (526.7981183503364, 276.45119434234476)),\n",
       " 93: ((1473.7305229697176, 5349.455018877206),\n",
       "  (5341.150293021474, 5675.75413282855)),\n",
       " 94: ((1473.7305229697176, 5262.7294129581405),\n",
       "  (5254.288675788735, 5053.138296550533)),\n",
       " 95: ((1473.7305229697176, 5262.7294129581405),\n",
       "  (5198.359091153799, 5053.138296550533)),\n",
       " 96: ((213.8881060128947, 272.4828179907058),\n",
       "  (286.62558461080994, 272.48281837978726)),\n",
       " 97: ((133.24224772826443, 9.659666962612455),\n",
       "  (134.8662176315823, 10.987194847318477))}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfgs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load cause-effect pairs: 100%|██████████| 100/100 [00:00<00:00, 311.85it/s]\n"
     ]
    }
   ],
   "source": [
    "best_gmm_full_scores = return_best_between_marginal_and_full_scores(\n",
    "    bayesgmm_scores, bfgs_scores \n",
    ")\n",
    "bayes_gmm_auc = get_auc_scores(data_name, best_gmm_full_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.515426497277677"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_gmm_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6986817325800376, GMM AUC: 0.515426497277677\n"
     ]
    }
   ],
   "source": [
    "print(f\"AUC: {adam_bfgs_auc}, GMM AUC: {bayes_gmm_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8d95aa7f610185758b0e4e87261a268c67bfd80b13e0d0c16090894e4422c34"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('gp-causal-3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
