{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Synthetic and Real results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will calculate the final results for the synthetic and real data.\n",
    "\n",
    "The datasets are:\n",
    "1. CE-Cha\n",
    "2. CE-Multi\n",
    "3. CE-Net\n",
    "4. CE-Gauss\n",
    "5. CE-Tueb\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKDIR = \"/vol/bitbucket/ad6013/Research/gp-causal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(WORKDIR)\n",
    "import dill\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from data import get_data\n",
    "from tqdm import trange\n",
    "from utils import BEST_SCORES\n",
    "from utils import return_all_scores, return_best_causal_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pairs(data_name):\n",
    "    synth_data_names = [\"cha\", \"multi\", \"net\", \"gauss\"]\n",
    "    if data_name in synth_data_names:\n",
    "        data_get = getattr(get_data, f\"get_{data_name}_pairs_dataset\")\n",
    "        x, y, weight, target = data_get(data_path=f\"{WORKDIR}/data/{data_name}_pairs/files\")\n",
    "    elif data_name == \"tueb\":\n",
    "        data_get = getattr(get_data, f\"get_tubingen_pairs_dataset\")\n",
    "        x, y, weight, target = data_get(data_path=f\"{WORKDIR}/data/pairs/files\")\n",
    "    else:\n",
    "        full_data_name = synth_data_names.append(\"tueb\")\n",
    "        raise ValueError(f\"data_name variable must be in {full_data_name}\")\n",
    "    return x, y, weight, target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File types for the results\n",
    "# The files may have different formats of results saved\n",
    "# For some datasets, there are multiple result files with different names\n",
    "# these will be returned as a list and the best results chosen \n",
    "# Indicator next to file will indicate what kind of format the results are\n",
    "# stored in\n",
    "\n",
    "def cha_result_files():\n",
    "    file_1 = [\n",
    "        f\"fullscore-cha_pairs-gplvm-reinit20-numind200_start:{i}_end:{i+150}.p\"\n",
    "        for i in np.linspace(0, 150, 2, dtype=int)\n",
    "    ]\n",
    "    file_2 = [\n",
    "        f\"fullscore-cha_pairs-gplvmgeneralised-reinit10-numind200_start:{i}_end:{i+20}.p\"\n",
    "        for i in np.linspace(0, 280, 15, dtype=int)\n",
    "     ]\n",
    "    return [(file_1, 0)]\n",
    "\n",
    "\n",
    "def multi_result_files():\n",
    "    files_1 = [\n",
    "        f\"fullscore-multi_pairs-gplvm-reinit20-numind200_start:{i}_end:{i+20}.p\"\n",
    "        for i in np.linspace(0, 280, 15, dtype=int)\n",
    "    ]\n",
    "    files_2 = [\n",
    "        f\"fullscore-multi_pairs-gplvm_adam-reinit2-numind200_start:{i}_end:{i+20}.p\"\n",
    "        for i in np.linspace(0, 280, 15, dtype=int)\n",
    "    ]\n",
    "    return [(files_2, 0), (files_1, 0)]\n",
    "\n",
    "\n",
    "def net_result_files():\n",
    "    files = [\n",
    "        f\"fullscore-net_pairs-gplvm-reinit20-numind200_start:{i}_end:{i+20}.p\"\n",
    "        for i in np.linspace(0, 280, 15, dtype=int)\n",
    "    ]\n",
    "    return [(files, 0)]\n",
    "\n",
    "\n",
    "def gauss_result_files():\n",
    "    files_1 = [\n",
    "        f\"fullscore-gauss_pairs-gplvm-reinit20-numind200_start:{i}_end:{i+20}.p\"\n",
    "        for i in np.linspace(0, 280, 15, dtype=int)\n",
    "    ]\n",
    "    files_2 = [\n",
    "        f\"fullscore-gauss_pairs-gplvm_adam-reinit2-numind200_start:{i}_end:{i+20}.p\"\n",
    "        for i in np.linspace(0, 280, 15, dtype=int)\n",
    "    ]\n",
    "    files_3 = [\n",
    "        f\"fullscore-gauss_pairs-gplvmgeneralised-reinit20-numind200_start:{i}_end:{i+20}.p\"\n",
    "        for i in np.linspace(0, 280, 15, dtype=int)\n",
    "    ]\n",
    "    return [ (files_3, 1)]\n",
    "\n",
    "\n",
    "def tueb_result_files():\n",
    "    files_1 = [\n",
    "        f\"fullscore-cep-gplvmgeneralised-reinit20-numind200_start:{i}_end:{i+5}.p\"\n",
    "        for i in np.linspace(0, 100, 21, dtype=int)\n",
    "    ]\n",
    "    files_2 = [\n",
    "        f\"fullscore-cep-gplvmgeneralised-reinit10-numind200_start:{i}_end:{i+5}.p\"\n",
    "        for i in np.linspace(0, 100, 21, dtype=int)\n",
    "    ]    \n",
    "    return [(files_2, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to put the results in the right format\n",
    "def extract_file(file_name):\n",
    "    with open(f\"{WORKDIR}/results/{file_name}\", \"rb\") as f:\n",
    "        result = dill.load(f)\n",
    "    return result\n",
    "\n",
    "\n",
    "def find_best_scores_tuples(all_files: list):\n",
    "    all_best_scores = {}\n",
    "    # Need a file counter so that the keys are the correct number\n",
    "    file_counter = 0 \n",
    "    for file in all_files:\n",
    "        result = extract_file(file)\n",
    "        for idx, scores in enumerate(result[\"scores\"]):\n",
    "            best_scores = BEST_SCORES(\n",
    "                scores[0][0], scores[0][1], scores[1][0], scores[1][1]\n",
    "            )\n",
    "            all_best_scores[idx + file_counter] = best_scores\n",
    "        # Need to find the index where the file ends\n",
    "        ending_idx = file[:-2].split(':')[-1]\n",
    "        file_counter = int(ending_idx)\n",
    "    return all_best_scores\n",
    "            \n",
    "\n",
    "def find_best_scores_from_dict(all_files: list):\n",
    "    all_results = {}\n",
    "    for file in all_files:\n",
    "        result = extract_file(file)\n",
    "        all_results.update(result[\"final_scores\"])\n",
    "\n",
    "    all_x, all_y_x, all_y, all_x_y = return_all_scores(all_results)\n",
    "    best_scores = return_best_causal_scores(all_x, all_y_x, all_y, all_x_y)\n",
    "    return best_scores\n",
    "\n",
    "\n",
    "def choose_best_scores(score_dict: dict):\n",
    "    \"\"\"Given multiple best score dicts, this will choose the best scores among\n",
    "    them.\n",
    "\n",
    "    Args:\n",
    "        dict (dict): Values are dicts with value of form BEST_SCORES \n",
    "        which is a names tuple with arguements 'best_loss_x best_loss_y_x \n",
    "        best_loss_y best_loss_x_y'.\n",
    "    \"\"\"\n",
    "    if len(score_dict.keys()) == 1:\n",
    "        return score_dict[0]\n",
    "    else:\n",
    "        num_datasets = len(score_dict[0].keys())\n",
    "        final_best_score = {}\n",
    "        # For each run, find the best score\n",
    "        all_run_idxs = score_dict[0].keys()\n",
    "        for run_idx in list(all_run_idxs):\n",
    "            all_dicts_this_run = [score_dict[i][run_idx] for i in list(score_dict.keys())]\n",
    "            x_scores = [d_loop.best_loss_x for d_loop in all_dicts_this_run]\n",
    "            y_x_scores = [d_loop.best_loss_y_x for d_loop in all_dicts_this_run]\n",
    "            y_scores = [d_loop.best_loss_y for d_loop in all_dicts_this_run]\n",
    "            x_y_scores = [d_loop.best_loss_x_y for d_loop in all_dicts_this_run]\n",
    "            best_scores_this_run = BEST_SCORES(\n",
    "                min(x_scores), min(y_x_scores), min(y_scores), min(x_y_scores)\n",
    "            )\n",
    "            final_best_score[run_idx] = best_scores_this_run\n",
    "        return final_best_score\n",
    "\n",
    "\n",
    "def get_final_scores_from_best_scores(best_scores):\n",
    "    total_runs = len(list(best_scores.keys()))\n",
    "    y_scores = {}\n",
    "    y_scores_array = np.zeros(total_runs)\n",
    "    for idx, run_idx in enumerate(list(best_scores.keys())):\n",
    "        current_run = best_scores[run_idx]\n",
    "        causal_score = current_run.best_loss_x + current_run.best_loss_y_x\n",
    "        anticausal_score = current_run.best_loss_y + current_run.best_loss_x_y\n",
    "        y_scores[run_idx] = - causal_score + anticausal_score\n",
    "        y_scores_array[idx] = - causal_score + anticausal_score \n",
    "    return y_scores, y_scores_array\n",
    "\n",
    "\n",
    "def balance_for_auc(target, pred_scores):\n",
    "    # Targets are {-1, 1}, need to make sure it sums to zero\n",
    "    balance = int(np.sum(target))\n",
    "    if balance != 0:\n",
    "        # There are more negative examples\n",
    "        if balance < 0:\n",
    "            switch_cand_idx = np.nonzero(target < 0)[0]\n",
    "        # There are more positive examples here\n",
    "        else:\n",
    "            switch_cand_idx = np.nonzero(target > 0)[0]\n",
    "        # get \"balance\" number of indices\n",
    "        switch_idx = np.random.choice(\n",
    "            switch_cand_idx, size=int(np.abs(balance) // 2), replace=False\n",
    "        )\n",
    "        final_target = target.copy()\n",
    "        final_target[switch_idx] *= -1\n",
    "        final_pred_scores = pred_scores.copy()\n",
    "        final_pred_scores[switch_idx] *= -1\n",
    "    else:\n",
    "        final_target = target.copy()\n",
    "        final_pred_scores = pred_scores.copy()\n",
    "    if (balance % 2) == 0:\n",
    "        assert np.sum(final_target) == 0\n",
    "    else:\n",
    "        assert np.abs(np.sum(final_target)) == 1\n",
    "    return final_target, final_pred_scores\n",
    "    \n",
    "\n",
    "def calculate_auc(target, pred_scores, num_shuffles=1000):\n",
    "    # Need to make sure that the classes are evenly balanced\n",
    "    auc_all = []\n",
    "    for i in trange(num_shuffles):\n",
    "        total_runs = len(target)\n",
    "        flip_idx = np.random.choice(np.arange(total_runs), total_runs // 2, replace=False)\n",
    "        for i in range(total_runs):\n",
    "            if i in flip_idx:\n",
    "                target[i] *= -1\n",
    "                pred_scores[i] *= -1\n",
    "        final_target, final_pred_scores = balance_for_auc(target, pred_scores)\n",
    "        roc_auc = roc_auc_score(final_target, final_pred_scores)\n",
    "        auc_all.append(roc_auc)\n",
    "    return np.mean(auc_all)\n",
    "\n",
    "\n",
    "def return_auc_results(data_name):\n",
    "    # Check the data name is correct\n",
    "    all_data_names = [\"cha\", \"multi\", \"net\", \"gauss\", \"tueb\"]\n",
    "    if data_name not in all_data_names:\n",
    "        raise ValueError(f\"data_name is not correct. Must be one of {all_data_names}\")\n",
    "    # Get the result files\n",
    "    all_result_files = eval(f\"{data_name}_result_files\")()\n",
    "    # processing of result file will be different for different data\n",
    "    # if the number of files is more than 1, we need to select the best one\n",
    "    best_score_dict = {}\n",
    "    for idx, result_files in enumerate(all_result_files):\n",
    "        actual_files, indicator = result_files\n",
    "        if indicator == 0:\n",
    "            best_scores = find_best_scores_tuples(all_files=actual_files)\n",
    "        else:\n",
    "            best_scores = find_best_scores_from_dict(all_files=actual_files)\n",
    "        best_score_dict[idx] = best_scores\n",
    "    final_best_score = choose_best_scores(best_score_dict)\n",
    "    # Find the final score by adding the causla and anticausal scores\n",
    "    _, final_scores = get_final_scores_from_best_scores(best_scores=final_best_score)\n",
    "    if data_name != \"tueb\":\n",
    "        _, _, _, target =  return_pairs(data_name=data_name)\n",
    "    else:\n",
    "        target = np.ones(99)\n",
    "    auc = calculate_auc(target=target, pred_scores=final_scores)\n",
    "    return auc, final_scores, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 735.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cha: 0.8191207111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 702.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi: 0.9771990666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 700.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net: 0.9885765777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 10:10:54.875928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:54.889659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:54.891285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:54.893119: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-20 10:10:54.894235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:54.895859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:54.897339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:55.401294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:55.402509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:55.403087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-20 10:10:55.403655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22133 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:08:00.0, compute capability: 8.6\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 689.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gauss: 0.8803990666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1462.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tueb: 0.7828681632653061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi is missing a run (run number 199 due to NaNs)\n",
    "for dn in [\"cha\", \"multi\", \"net\", \"gauss\", \"tueb\"]:\n",
    "    auc, score, target = return_auc_results(data_name=dn)\n",
    "    print(f\"{dn}: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WORKDIR}/results/fullscore-multi_pairs-gplvm-reinit20-numind200_start:180_end:200.p\", \"rb\") as f:\n",
    "    result = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((2128.4078288203445, 1510.6619911914863),\n",
       "  (1919.335969284949, 1653.3660872558987)),\n",
       " ((2128.4078162017154, 1394.383803719083),\n",
       "  (1909.3119971328852, 1554.9223575693181)),\n",
       " ((1928.258421960225, -443.6584134761615),\n",
       "  (33.3228250361326, 1499.022160586228)),\n",
       " ((1683.388408728003, 1055.2079998635677),\n",
       "  (2128.4078190196906, 261.9700739423107)),\n",
       " ((2128.4078221497507, -125.04770111370397),\n",
       "  (2128.4078481815973, -294.26330495430466)),\n",
       " ((2007.419390350712, 1559.8575973586412),\n",
       "  (1889.0740192001977, 1896.1966678291365)),\n",
       " ((2128.4078342848843, -213.3390138456706),\n",
       "  (1718.967175075185, 409.03829022199216)),\n",
       " ((2090.0999416530885, 607.4099149729673),\n",
       "  (1889.2802452300093, 753.1940218845889)),\n",
       " ((2128.407815342783, -47.218483020004896),\n",
       "  (338.35037724327685, 1819.9324041433656)),\n",
       " ((370.28288897569746, 1684.404157236906),\n",
       "  (1934.5992372447909, -241.08342386278628)),\n",
       " ((1932.6792273422443, -153.16066690662637),\n",
       "  (1451.1078732045626, 363.5866427548176)),\n",
       " ((2085.171991545442, 1760.5147948719182),\n",
       "  (1934.2863272095392, 2046.9195944864998)),\n",
       " ((2128.4078101065206, -363.45194302568416),\n",
       "  (1414.5665036724613, 564.8416452360048)),\n",
       " ((2083.696641184494, 1698.1059353147125),\n",
       "  (1893.1400783389763, 1612.7573055135995)),\n",
       " ((2128.4078172936033, 563.711247181245),\n",
       "  (1958.1201202923849, 818.5486548074405)),\n",
       " ((2060.654888770696, 755.4096635720698),\n",
       "  (1954.6890513647213, 660.4088619315548)),\n",
       " ((2128.4078087648168, 1231.764856140394),\n",
       "  (1997.1957758916706, 1635.3832160763568)),\n",
       " ((2128.407834458234, 1436.1769239269297),\n",
       "  (2114.407664767196, 1641.0164804164287)),\n",
       " ((1985.1231068435573, 1659.9424126175063),\n",
       "  (1923.0540249327278, 1421.6818382659171)),\n",
       " ((inf, inf), (inf, inf))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8d95aa7f610185758b0e4e87261a268c67bfd80b13e0d0c16090894e4422c34"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('gp-causal-3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
